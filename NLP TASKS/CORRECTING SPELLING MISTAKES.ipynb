{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdfde61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "import nltk\n",
    "# nltk.download(\"words\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5697e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pasted from wikipedia\n",
    "# right side words are most commonly mispelled\n",
    "\n",
    "mis_spelled_words=\"\"\"absence – absense, absentse, abcense, absance[3][10]\n",
    "acceptable – acceptible[4]\n",
    "accidentally/accidently – accidentaly[4]\n",
    "accommodate – accomodate, acommodate[3][4]\n",
    "achieve – acheive[3]\n",
    "acknowledge – acknowlege, aknowledge[3]\n",
    "acquaintance – acquaintence, aquaintance[3]\n",
    "acquire – aquire, adquire[4]\n",
    "acquit – aquit[4]\n",
    "calendar – calender[3][4]\n",
    "camouflage – camoflage, camoflague[3]\n",
    "capitol – capital[3] (both words exist, but are distinct)\n",
    "Caribbean – Carribean[3]\n",
    "category – catagory[3][4]\n",
    "caught – cauhgt, caugt[3]\n",
    "cemetery – cemetary,[1] cematery[3]\n",
    "changeable – changable[3][4]\n",
    "chief – cheif[3]\n",
    "embarrass – embarass[1][4]\n",
    "equipment – equiptment (wrong in numerous webpages)[4]\n",
    "exceed – excede[4]\n",
    "exhilarate – exilerate[4]\n",
    "ignorance – ignorence[4]\n",
    "imitate – immitate[3]\n",
    "immediately – imediately[\n",
    "readable – readible[8]\n",
    "really – realy[1]\n",
    "receive – recieve[1][4]\n",
    "receipt – reciept[4]\n",
    "tyranny – tyrany[4]\n",
    "underrate – underate[4]\n",
    "until – untill[4]\n",
    "upholstery – upholstry[4]\n",
    "welfare – wellfare, welfair[3]\n",
    "whether – wether[3]\n",
    "wilful – wilfull (American: willful)[1]\n",
    "withhold – withold[1]\n",
    "writing – writting, writeing[10]\n",
    "skilful – skilfull (American: skillful)[1]\n",
    "speech – speach, speeche (archaic)[10]\n",
    "successful – succesful, successfull, sucessful[1]\n",
    "supersede – supercede[4]\n",
    "surprise – suprise, surprize[1]\n",
    "playwright – playright, playwrite[4]\n",
    "possession – posession, possesion[1][4]\n",
    "potatoes – potatos[1]\n",
    "precede – preceed[4]\n",
    "presence – presance[1]\n",
    "principle – principal[4]\n",
    "height – heighth, heigth[4]\n",
    "hierarchy – heirarchy[4]\n",
    "hors d'oeuvres – hors derves, ordeurves[3]\n",
    "humorous – humerous[4]\n",
    "hygiene – hygene, hygine, hiygeine, higeine, hygeine[3]\n",
    "hypocrisy/hypocrite – hipocrit[1]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21171d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_spelled_words=mis_spelled_words.split(\"\\n\")  #making doc string to list of sentence\n",
    "\n",
    "mis_spelled_words=[i.split(\"–\")[1].strip()  for i in mis_spelled_words]   #splitting them and get only wrong words\n",
    "\n",
    "list_of_words=[]          # storing words in array\n",
    "for i in mis_spelled_words:\n",
    "    list_of_words.append(re.sub(\"[^a-zA-Z]\",\" \",i).split()[0])         # getting only words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6fa937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"misspelled_words\":list_of_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a054e69a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelled_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acceptible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accidentaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accomodate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acheive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  misspelled_words\n",
       "0          absense\n",
       "1       acceptible\n",
       "2      accidentaly\n",
       "3       accomodate\n",
       "4          acheive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e929f",
   "metadata": {},
   "source": [
    "# EDIT DISTANCE/LEVENSHTEIN DISTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78463466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING EDIT DISTANCE METHOD TO FIND SIMILAR WORDS \n",
    "# HAVING MINIMUM DISTANCE IS TAKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d90a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation(w1,w2,show_arr=True):\n",
    "    w1=\"#\"+w1\n",
    "    w2=\"#\"+w2\n",
    "    arr=[[0]*len(w1)]*len(w2)\n",
    "    arr=np.zeros(len(w1)*len(w2)).reshape((len(w2),len(w1)))\n",
    "    arr[0,:]=[*range(0,len(w1))]\n",
    "    arr[:,0]=[*range(0,len(w2))]\n",
    "\n",
    "    for i in range(1,len(w2)):\n",
    "        for j in range(1,len(w1)):\n",
    "            if w1[j]==w2[i]:\n",
    "    #             print(i,j)\n",
    "                arr[i,j]=arr[i-1,j-1]\n",
    "    #             print(w1[j],w2[i],\"==>\",arr[i,j])\n",
    "            else:\n",
    "    #             print(i,j)\n",
    "                arr[i,j]=min(arr[i-1,j],arr[i,j-1],arr[i-1,j-1])+1\n",
    "#     print(\"The distance between them \",arr[-1,-1])\n",
    "    if show_arr:\n",
    "        return arr[-1,-1],w2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59bd8405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 'channae')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EG:\n",
    "relation(\"chennai\",\"channae\")  # returns diatance and word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa2c28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of words the nltk has : 236736\n"
     ]
    }
   ],
   "source": [
    "word_dict=words.words()                   # nltk getting list of all words\n",
    "print(\"the number of words the nltk has :\",len(word_dict))\n",
    "def nearest_words(word):\n",
    "    \n",
    "    same_first_letter=[]\n",
    "    similar_words=[]\n",
    "    for i in word_dict:\n",
    "        if i.startswith(word[0]):                    #assuming first letter is same for correct and misspelled words\n",
    "            same_first_letter.append(i)                 # to filter the words it is used\n",
    "            \n",
    "    for i in same_first_letter:\n",
    "        similar_words.append(relation(word,i))                            # getting distance for each word\n",
    "    similar_words=sorted(similar_words,key=lambda x:x[0],reverse=False)   # sorting based on distance\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e39fefd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'avid'),\n",
       " (1.0, 'acid'),\n",
       " (1.0, 'aid'),\n",
       " (1.0, 'amid'),\n",
       " (1.0, 'arid'),\n",
       " (1.0, 'avoid'),\n",
       " (1.0, 'acid'),\n",
       " (2.0, 'abed'),\n",
       " (2.0, 'abide'),\n",
       " (2.0, 'abidi')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EG:\n",
    "nearest_words(\"avid\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ba8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"correct_words1\"]=df[\"misspelled_words\"].apply(lambda x :nearest_words(x)[0][1])\n",
    "df[\"correct_words2\"]=df[\"misspelled_words\"].apply(lambda x :nearest_words(x)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0844c998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelled_words</th>\n",
       "      <th>correct_words1</th>\n",
       "      <th>correct_words2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absense</td>\n",
       "      <td>absence</td>\n",
       "      <td>abscise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acceptible</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>accendible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accidentaly</td>\n",
       "      <td>accidental</td>\n",
       "      <td>accidentally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accomodate</td>\n",
       "      <td>accommodate</td>\n",
       "      <td>accommodable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acheive</td>\n",
       "      <td>achene</td>\n",
       "      <td>achete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acknowlege</td>\n",
       "      <td>acknowledge</td>\n",
       "      <td>acknowledged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acquaintence</td>\n",
       "      <td>acquaintance</td>\n",
       "      <td>acquaintancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aquire</td>\n",
       "      <td>acquire</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aquit</td>\n",
       "      <td>acquit</td>\n",
       "      <td>absit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>calender</td>\n",
       "      <td>calender</td>\n",
       "      <td>calander</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  misspelled_words correct_words1 correct_words2\n",
       "0          absense        absence        abscise\n",
       "1       acceptible     acceptable     accendible\n",
       "2      accidentaly     accidental   accidentally\n",
       "3       accomodate    accommodate   accommodable\n",
       "4          acheive         achene         achete\n",
       "5       acknowlege    acknowledge   acknowledged\n",
       "6     acquaintence   acquaintance   acquaintancy\n",
       "7           aquire        acquire       acquired\n",
       "8            aquit         acquit          absit\n",
       "9         calender       calender       calander"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bb16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_venv",
   "language": "python",
   "name": "pandas_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
